{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe_root = '../'  # this file should be run from {caffe_root}/examples (otherwise change this line)\n",
    "\n",
    "import sys\n",
    "sys.path.insert(0, caffe_root + 'python')\n",
    "sys.path.insert(0, caffe_root + 'examples/tripletloss')\n",
    "import caffe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tripletloss/tripletloss_layer.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile tripletloss/tripletloss_layer.py\n",
    "import caffe\n",
    "import numpy as np\n",
    "\n",
    "class TripletLossLayer(caffe.Layer):\n",
    "    \"\"\"\n",
    "    Compute the Triplet Loss based on the Google's FaceNet paper.\n",
    "    \"\"\"\n",
    "\n",
    "    def setup(self, bottom, top):\n",
    "        # check if input pair is a triplet\n",
    "        if len(bottom) != 3:\n",
    "            raise Exception(\"Need three inputs to compute triplet loss. The bottom length was {}\".format(len(bottom)))\n",
    "            \n",
    "        params = eval(self.param_str)\n",
    "        try:\n",
    "            self.margin = float(params['margin'])\n",
    "        except:\n",
    "            self.margin = 1.0\n",
    "            \n",
    "        try:\n",
    "            self.debug = params['debug']\n",
    "        except:\n",
    "            self.debug = 0\n",
    "\n",
    "    def reshape(self, bottom, top):\n",
    "        # check input shapes match\n",
    "        if bottom[0].count != bottom[1].count or bottom[1].count != bottom[2].count:\n",
    "            raise Exception(\"Inputs must have the same dimension.\")\n",
    "        # differences are shape of inputs\n",
    "        self.diff_pos = np.zeros_like(bottom[0].data, dtype=np.float32)\n",
    "        self.diff_neg = np.zeros_like(bottom[0].data, dtype=np.float32)\n",
    "        # normalized\n",
    "        self.norm_anc = bottom[0].data\n",
    "        self.log('norm_anc = {}'.format(self.norm_anc))\n",
    "        self.norm_pos = bottom[1].data\n",
    "        self.log('norm_pos = {}'.format(self.norm_pos))\n",
    "        self.norm_neg = bottom[2].data\n",
    "        self.log('norm_neg = {}'.format(self.norm_neg))\n",
    "        # loss\n",
    "        self.batch_size = bottom[0].data.shape[0]\n",
    "        self.log('batch_size = {}'.format(self.batch_size))\n",
    "        self.loss = np.zeros(self.batch_size, dtype=np.float32)\n",
    "        # loss output is scalar\n",
    "        top[0].reshape(1)\n",
    "\n",
    "    def forward(self, bottom, top):\n",
    "        \"\"\" computes a loss\n",
    "        Loss = SUM[i->N](Di_pos - Di_neg + margin), 0 <= i <= N(the batch size)\n",
    "        Dpos = sqrt(L2(IMGi_anc - IMGi_pos))\n",
    "        Dneg = sqrt(L2(IMGi_anc - IMGi_neg))\n",
    "        \"\"\"\n",
    "        \n",
    "        self.diff_pos[...] = self.norm_anc - self.norm_pos\n",
    "        self.log('diff_pos = {}'.format(self.diff_pos))\n",
    "        self.diff_neg[...] = self.norm_anc - self.norm_neg\n",
    "        self.log('diff_neg = {}'.format(self.diff_neg))\n",
    "        dist_pos = np.sum(self.diff_pos**2, axis=1)\n",
    "        self.log('dist_pos = {}'.format(dist_pos))\n",
    "        dist_neg = np.sum(self.diff_neg**2, axis=1)\n",
    "        self.log('dist_neg = {}'.format(dist_neg))\n",
    "        # calculate a loss for each item\n",
    "        for i in range(self.batch_size):\n",
    "            loss = dist_pos[i] - dist_neg[i] + self.margin\n",
    "            self.log('loss[{}] = {}'.format(i, loss))\n",
    "            self.loss[i] = max(0, loss)\n",
    "        total_loss = np.sum(self.loss)\n",
    "        self.log('total loss = {}, mini_batch_size={}'.format(total_loss, self.batch_size))\n",
    "        top[0].data[...] = total_loss / self.batch_size\n",
    "\n",
    "    def backward(self, top, propagate_down, bottom):\n",
    "        \"\"\" computes a gradient w.r.t. each IMG\n",
    "        dL/dDanc = SUM[i->N]{2(IMGi_neg - IMGi_pos)} if Lossi > 0 else 0\n",
    "        dL/dDpos = SUM[i->N](-2(IMGi_anc - IMGi_pos)) if Lossi > 0 else 0\n",
    "        dL/dDneg = SUM[i->N](2(IMGi_anc - IMGi_neg)) if Lossi > 0 else 0\n",
    "        \"\"\"\n",
    "        # gradient w.r.t. Danc\n",
    "        diff_org = self.norm_neg - self.norm_pos\n",
    "        for i in range(self.batch_size):\n",
    "            if self.loss[i] == 0:\n",
    "                diff_org[i] = 0\n",
    "        bottom[0].diff[...] = 2 * diff_org\n",
    "        self.log('anc diff = {}'.format(bottom[0].diff))\n",
    "        \n",
    "        # gradient w.r.t. Dpos\n",
    "        for i in range(self.batch_size):\n",
    "            self.diff_pos[i] = 0\n",
    "        bottom[1].diff[...] = -2 * self.diff_pos\n",
    "        self.log('pos diff = {}'.format(bottom[1].diff))\n",
    "        \n",
    "        # gradient w.r.t. Dneg\n",
    "        for i in range(self.batch_size):\n",
    "            self.diff_neg[i] = 0\n",
    "        bottom[2].diff[...] = 2 * self.diff_neg\n",
    "        self.log('neg diff = {}'.format(bottom[2].diff))\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.debug == 0:\n",
    "            return\n",
    "        \n",
    "        print(message)\n",
    "        \n",
    "class PairwiseDistanceLayer(caffe.Layer):\n",
    "    \n",
    "    def setup(self, bottom, top):\n",
    "        # check input pair\n",
    "        if len(bottom) != 2:\n",
    "            raise Exception(\"Need two inputs to compute a pair wise distance. The bottom length was {}\".format(len(bottom)))\n",
    "            \n",
    "        params = eval(self.param_str)\n",
    "        try:\n",
    "            self.debug = params['debug']\n",
    "        except:\n",
    "            self.debug = 0\n",
    "        \n",
    "    def reshape(self, bottom, top):\n",
    "        # check input shapes match\n",
    "        if bottom[0].count != bottom[1].count:\n",
    "            raise Exception(\"Inputs must have the same dimension.\")\n",
    "            \n",
    "        self.batch_size = bottom[0].data.shape[0]\n",
    "        top[0].reshape(1)\n",
    "            \n",
    "    def forward(self, bottom, top):\n",
    "        \"\"\" computes a distance\n",
    "        Dpos = sqrt(L2(IMGi_acr - IMGi_pos))\n",
    "        \"\"\"\n",
    "        dist = np.sum((bottom[0].data - bottom[1].data)**2, axis=1)\n",
    "        self.log('L2 squared dist = {}'.format(dist))\n",
    "        top[0].data[...] = np.sum(dist) / self.batch_size\n",
    "        \n",
    "    def log(self, message):\n",
    "        if self.debug == 0:\n",
    "            return\n",
    "        \n",
    "        print(message)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Test Forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tempfile\n",
    "import numpy as np\n",
    "from caffe import layers as L, params as P\n",
    "\n",
    "def load_net(net_proto):\n",
    "    f = tempfile.NamedTemporaryFile(mode='w+', delete=False)\n",
    "    f.write(str(net_proto))\n",
    "    f.close()\n",
    "    return caffe.Net(f.name, caffe.TEST)\n",
    "\n",
    "def l2normed(embeddings, dim):\n",
    "    \"\"\"Returns L2-normalized instances of vec; i.e., for each instance x in embeddings,\n",
    "    computes  x / ((x ** 2).sum() ** 0.5). Assumes embeddings has shape N x dim.\"\"\"\n",
    "    denom = L.Reduction(embeddings, axis=1, operation=P.Reduction.SUMSQ)\n",
    "    denom = L.Power(denom, power=(-0.5))\n",
    "    denom = L.Reshape(denom, num_axes=0, axis=-1, shape=dict(dim=[1]))\n",
    "    denom = L.Tile(denom, axis=1, tiles=dim)\n",
    "    return L.Eltwise(embeddings, denom, operation=P.Eltwise.PROD)\n",
    "\n",
    "def example_network(batch_size):\n",
    "    n = caffe.NetSpec()\n",
    "\n",
    "    # we use the dummy data layer to control the \n",
    "    # shape of the inputs to the layer we are testing\n",
    "    ip_dims = [3*batch_size, 3]\n",
    "    label_dims = [batch_size]\n",
    "    n.ip, n.label = L.DummyData(shape=[dict(dim=ip_dims),dict(dim=label_dims)],\n",
    "                                        transform_param=dict(scale=1.0/255.0),\n",
    "                                        ntop=2)\n",
    "    \n",
    "    n.slice_anc, n.slice_pos, n.slice_neg = L.Slice(n.ip, slice_param=dict(axis=0), ntop=3)\n",
    "    n.slice_anc_norm = l2normed(n.slice_anc, 3)\n",
    "    n.slice_pos_norm = l2normed(n.slice_pos, 3)\n",
    "    n.slice_neg_norm = l2normed(n.slice_neg, 3)\n",
    "    n.triplet = L.Python(n.slice_anc_norm, n.slice_pos_norm, n.slice_neg_norm, loss_weight=1, python_param=dict(module='tripletloss_layer', layer='TripletLossLayer', param_str='{\\\"margin\\\": 1.0, \\\"debug\\\": 1}'))\n",
    "    return n.to_proto()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings shape = (3, 3)\n",
      "norm_anc = [[ 0.  0.  0.]]\n",
      "norm_pos = [[ 0.  0.  0.]]\n",
      "norm_neg = [[ 0.  0.  0.]]\n",
      "batch_size = 1\n",
      "norm_anc = [[ 0.57735026  0.57735026  0.57735026]]\n",
      "norm_pos = [[ 0.57735026  0.57735026  0.57735026]]\n",
      "norm_neg = [[ nan  nan  nan]]\n",
      "batch_size = 1\n",
      "diff_pos = [[ 0.  0.  0.]]\n",
      "diff_neg = [[ nan  nan  nan]]\n",
      "dist_pos = [ 0.]\n",
      "dist_neg = [ nan]\n",
      "loss[0] = nan\n",
      "total loss = 0.0, mini_batch_size=1\n",
      "ip\n",
      "value = [[ 1.  1.  1.]\n",
      " [ 1.  1.  1.]\n",
      " [ 0.  0.  0.]]\n",
      "label\n",
      "value = [ 0.]\n",
      "slice_anc\n",
      "value = [[ 1.  1.  1.]]\n",
      "slice_pos\n",
      "value = [[ 1.  1.  1.]]\n",
      "slice_neg\n",
      "value = [[ 0.  0.  0.]]\n",
      "slice_anc_slice_anc_0_split_0\n",
      "value = [[ 1.  1.  1.]]\n",
      "slice_anc_slice_anc_0_split_1\n",
      "value = [[ 1.  1.  1.]]\n",
      "slice_pos_slice_anc_1_split_0\n",
      "value = [[ 1.  1.  1.]]\n",
      "slice_pos_slice_anc_1_split_1\n",
      "value = [[ 1.  1.  1.]]\n",
      "slice_neg_slice_anc_2_split_0\n",
      "value = [[ 0.  0.  0.]]\n",
      "slice_neg_slice_anc_2_split_1\n",
      "value = [[ 0.  0.  0.]]\n",
      "Reduction1\n",
      "value = [ 3.]\n",
      "Power1\n",
      "value = [ 0.57735026]\n",
      "Reshape1\n",
      "value = [[ 0.57735026]]\n",
      "Tile1\n",
      "value = [[ 0.57735026  0.57735026  0.57735026]]\n",
      "slice_anc_norm\n",
      "value = [[ 0.57735026  0.57735026  0.57735026]]\n",
      "Reduction2\n",
      "value = [ 3.]\n",
      "Power2\n",
      "value = [ 0.57735026]\n",
      "Reshape2\n",
      "value = [[ 0.57735026]]\n",
      "Tile2\n",
      "value = [[ 0.57735026  0.57735026  0.57735026]]\n",
      "slice_pos_norm\n",
      "value = [[ 0.57735026  0.57735026  0.57735026]]\n",
      "Reduction3\n",
      "value = [ 0.]\n",
      "Power3\n",
      "value = [ inf]\n",
      "Reshape3\n",
      "value = [[ inf]]\n",
      "Tile3\n",
      "value = [[ inf  inf  inf]]\n",
      "slice_neg_norm\n",
      "value = [[ nan  nan  nan]]\n",
      "triplet\n",
      "value = [ 0.]\n",
      "running backward...\n",
      "diff anc = [[ 0.  0.  0.]]\n",
      "diff pos = [[ 0.  0.  0.]]\n",
      "diff neg = [[ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "IMG_ANC = [1.0, 1.0, 1.0]\n",
    "# ||f(IMG_ANC)||_2 = sqrt(1**2 + 1**2 + 1**2) = 1.73...\n",
    "IMG_POS = [1.0, 1.0, 1.0]\n",
    "# ||f(IMG_POS)||_2 = sqrt(1**2 + 1**2 + 1**2) = 1.73...\n",
    "IMG_NEG = [0., 0., 0.]\n",
    "# ||f(IMG_NEG)||_2 = sqrt(0**2 + 0**2 + 0**2) = 0\n",
    "\n",
    "# embeddings is an 1D-array of features\n",
    "# here, the size of features is 3, 3*32bit = 96bit\n",
    "# (batch_size, feature_size)\n",
    "embeddings = np.array([IMG_ANC, IMG_POS, IMG_NEG], dtype=np.float32)\n",
    "print('embeddings shape = {}'.format(embeddings.shape))\n",
    "\n",
    "net_proto = example_network(1)\n",
    "with open('tripletloss/mnist_tripletloss_train_test_10_auto.prototxt', 'w') as f:\n",
    "    f.write(str(net_proto))\n",
    "net = load_net(net_proto)\n",
    "net.blobs['ip'].data[...] = embeddings\n",
    "\n",
    "net.forward()\n",
    "\n",
    "for name in net.blobs:\n",
    "    print('{}'.format(name))\n",
    "    print('value = {}'.format(net.blobs[name].data))\n",
    "    \n",
    "print('running backward...')\n",
    "net.backward()\n",
    "\n",
    "print('diff anc = {}'.format(net.blobs['slice_anc'].diff))\n",
    "print('diff pos = {}'.format(net.blobs['slice_pos'].diff))\n",
    "print('diff neg = {}'.format(net.blobs['slice_neg'].diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "embeddings shape = (3, 3)\n",
      "norm_anc = [[ 0.  0.  0.]]\n",
      "norm_pos = [[ 0.  0.  0.]]\n",
      "norm_neg = [[ 0.  0.  0.]]\n",
      "batch_size = 1\n",
      "norm_anc = [[ 0.0993808   0.0496904   0.99380797]]\n",
      "norm_pos = [[ 0.80178374  0.26726124  0.53452247]]\n",
      "norm_neg = [[ 0.89428413  0.01788568  0.44714206]]\n",
      "batch_size = 1\n",
      "diff_pos = [[-0.70240295 -0.21757084  0.4592855 ]]\n",
      "diff_neg = [[-0.79490334  0.03180472  0.54666591]]\n",
      "dist_pos = [ 0.75165015]\n",
      "dist_neg = [ 0.93172652]\n",
      "loss[0] = 0.819923639297\n",
      "total loss = 0.819923639297, mini_batch_size=1\n",
      "ip\n",
      "value = [[  10.    5.  100.]\n",
      " [  30.   10.   20.]\n",
      " [ 100.    2.   50.]]\n",
      "label\n",
      "value = [ 0.]\n",
      "slice_anc\n",
      "value = [[  10.    5.  100.]]\n",
      "slice_pos\n",
      "value = [[ 30.  10.  20.]]\n",
      "slice_neg\n",
      "value = [[ 100.    2.   50.]]\n",
      "slice_anc_slice_anc_0_split_0\n",
      "value = [[  10.    5.  100.]]\n",
      "slice_anc_slice_anc_0_split_1\n",
      "value = [[  10.    5.  100.]]\n",
      "slice_pos_slice_anc_1_split_0\n",
      "value = [[ 30.  10.  20.]]\n",
      "slice_pos_slice_anc_1_split_1\n",
      "value = [[ 30.  10.  20.]]\n",
      "slice_neg_slice_anc_2_split_0\n",
      "value = [[ 100.    2.   50.]]\n",
      "slice_neg_slice_anc_2_split_1\n",
      "value = [[ 100.    2.   50.]]\n",
      "Reduction1\n",
      "value = [ 10125.]\n",
      "Power1\n",
      "value = [ 0.00993808]\n",
      "Reshape1\n",
      "value = [[ 0.00993808]]\n",
      "Tile1\n",
      "value = [[ 0.00993808  0.00993808  0.00993808]]\n",
      "slice_anc_norm\n",
      "value = [[ 0.0993808   0.0496904   0.99380797]]\n",
      "Reduction2\n",
      "value = [ 1400.]\n",
      "Power2\n",
      "value = [ 0.02672612]\n",
      "Reshape2\n",
      "value = [[ 0.02672612]]\n",
      "Tile2\n",
      "value = [[ 0.02672612  0.02672612  0.02672612]]\n",
      "slice_pos_norm\n",
      "value = [[ 0.80178374  0.26726124  0.53452247]]\n",
      "Reduction3\n",
      "value = [ 12504.]\n",
      "Power3\n",
      "value = [ 0.00894284]\n",
      "Reshape3\n",
      "value = [[ 0.00894284]]\n",
      "Tile3\n",
      "value = [[ 0.00894284  0.00894284  0.00894284]]\n",
      "slice_neg_norm\n",
      "value = [[ 0.89428413  0.01788568  0.44714206]]\n",
      "triplet\n",
      "value = [ 0.81992364]\n",
      "running backward...\n",
      "diff anc = [[ 0.  0.  0.]]\n",
      "diff pos = [[ 0.  0.  0.]]\n",
      "diff neg = [[ 0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "IMG_ANC = [10.0, 5.0, 100.0]\n",
    "IMG_POS = [30.0, 10.0, 20.0]\n",
    "IMG_NEG = [100., 2., 50.]\n",
    "embeddings = np.array([IMG_ANC, IMG_POS, IMG_NEG], dtype=np.float32)\n",
    "print('embeddings shape = {}'.format(embeddings.shape))\n",
    "\n",
    "net_proto = example_network(1)\n",
    "net = load_net(net_proto)\n",
    "net.blobs['ip'].data[...] = embeddings\n",
    "\n",
    "net.forward()\n",
    "\n",
    "for name in net.blobs:\n",
    "    print('{}'.format(name))\n",
    "    print('value = {}'.format(net.blobs[name].data))\n",
    "    \n",
    "print('running backward...')\n",
    "net.backward()\n",
    "\n",
    "print('diff anc = {}'.format(net.blobs['slice_anc'].diff))\n",
    "print('diff pos = {}'.format(net.blobs['slice_pos'].diff))\n",
    "print('diff neg = {}'.format(net.blobs['slice_neg'].diff))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hello Training with MNIST\n",
    "\n",
    "embeddings size = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tripletloss/mnist_tripletloss_train_test_10.prototxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile tripletloss/mnist_tripletloss_train_test_10.prototxt\n",
    "name: \"mnist_tripletloss_train_test_10\"\n",
    "layer {\n",
    "  name: \"triplet_data\"\n",
    "  type: \"ImageData\"\n",
    "  top: \"triplet_data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  image_data_param {\n",
    "    source: \"/home/researcher/caffe-tripletloss/examples/tripletloss/mnist/trainlist_64.txt\"\n",
    "    batch_size: 192\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"triplet_data\"\n",
    "  type: \"ImageData\"\n",
    "  top: \"triplet_data\"\n",
    "  top: \"label\"\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "  transform_param {\n",
    "    scale: 0.00390625\n",
    "  }\n",
    "  image_data_param {\n",
    "    source: \"/home/researcher/caffe-tripletloss/examples/tripletloss/mnist/trainlist_64.txt\"\n",
    "    batch_size: 192\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"slice_triplet\"\n",
    "  type: \"Slice\"\n",
    "  bottom: \"triplet_data\"\n",
    "  top: \"anchor\"\n",
    "  top: \"positive\"\n",
    "  top: \"negative\"\n",
    "  slice_param {\n",
    "    slice_dim: 0\n",
    "  }\n",
    "}\n",
    "\n",
    "################# ANCHOR #############\n",
    "layer {\n",
    "  name: \"conv1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"anchor\"\n",
    "  top: \"conv1\"\n",
    "  param {\n",
    "    name: \"conv1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"pool1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv2\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool1\"\n",
    "  top: \"conv2\"\n",
    "  param {\n",
    "    name: \"conv2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool2\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv2\"\n",
    "  top: \"pool2\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool2\"\n",
    "  top: \"ip1\"\n",
    "  param {\n",
    "    name: \"ip1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip1\"\n",
    "  top: \"ip1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip1\"\n",
    "  top: \"feat\"\n",
    "  param {\n",
    "    name: \"ip2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "###################### POSITIVE ###################\n",
    "\n",
    "layer {\n",
    "  name: \"conv1_p\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"positive\"\n",
    "  top: \"conv1_p\"\n",
    "  param {\n",
    "    name: \"conv1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1_p\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1_p\"\n",
    "  top: \"pool1_p\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv2_p\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool1_p\"\n",
    "  top: \"conv2_p\"\n",
    "  param {\n",
    "    name: \"conv2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool2_p\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv2_p\"\n",
    "  top: \"pool2_p\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1_p\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool2_p\"\n",
    "  top: \"ip1_p\"\n",
    "  param {\n",
    "    name: \"ip1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1_p\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip1_p\"\n",
    "  top: \"ip1_p\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip2_p\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip1_p\"\n",
    "  top: \"feat_p\"\n",
    "  param {\n",
    "    name: \"ip2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "######################### NEGATIVE #########################\n",
    "\n",
    "layer {\n",
    "  name: \"conv1_n\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"negative\"\n",
    "  top: \"conv1_n\"\n",
    "  param {\n",
    "    name: \"conv1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1_n\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1_n\"\n",
    "  top: \"pool1_n\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv2_n\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool1_n\"\n",
    "  top: \"conv2_n\"\n",
    "  param {\n",
    "    name: \"conv2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool2_n\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv2_n\"\n",
    "  top: \"pool2_n\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1_n\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool2_n\"\n",
    "  top: \"ip1_n\"\n",
    "  param {\n",
    "    name: \"ip1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1_n\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip1_n\"\n",
    "  top: \"ip1_n\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip2_n\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip1_n\"\n",
    "  top: \"feat_n\"\n",
    "  param {\n",
    "    name: \"ip2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "############# L2 Normalization ############\n",
    "\n",
    "layer {\n",
    "  name: \"Reduction1\"\n",
    "  type: \"Reduction\"\n",
    "  bottom: \"feat\"\n",
    "  top: \"Reduction1\"\n",
    "  reduction_param {\n",
    "    operation: SUMSQ\n",
    "    axis: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Power1\"\n",
    "  type: \"Power\"\n",
    "  bottom: \"Reduction1\"\n",
    "  top: \"Power1\"\n",
    "  power_param {\n",
    "    power: -0.5\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reshape1\"\n",
    "  type: \"Reshape\"\n",
    "  bottom: \"Power1\"\n",
    "  top: \"Reshape1\"\n",
    "  reshape_param {\n",
    "    shape {\n",
    "      dim: 1\n",
    "    }\n",
    "    axis: -1\n",
    "    num_axes: 0\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Tile1\"\n",
    "  type: \"Tile\"\n",
    "  bottom: \"Reshape1\"\n",
    "  top: \"Tile1\"\n",
    "  tile_param {\n",
    "    axis: 1\n",
    "    tiles: 10\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"slice_anc_norm\"\n",
    "  type: \"Eltwise\"\n",
    "  bottom: \"feat\"\n",
    "  bottom: \"Tile1\"\n",
    "  top: \"slice_anc_norm\"\n",
    "  eltwise_param {\n",
    "    operation: PROD\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reduction2\"\n",
    "  type: \"Reduction\"\n",
    "  bottom: \"feat_p\"\n",
    "  top: \"Reduction2\"\n",
    "  reduction_param {\n",
    "    operation: SUMSQ\n",
    "    axis: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Power2\"\n",
    "  type: \"Power\"\n",
    "  bottom: \"Reduction2\"\n",
    "  top: \"Power2\"\n",
    "  power_param {\n",
    "    power: -0.5\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reshape2\"\n",
    "  type: \"Reshape\"\n",
    "  bottom: \"Power2\"\n",
    "  top: \"Reshape2\"\n",
    "  reshape_param {\n",
    "    shape {\n",
    "      dim: 1\n",
    "    }\n",
    "    axis: -1\n",
    "    num_axes: 0\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Tile2\"\n",
    "  type: \"Tile\"\n",
    "  bottom: \"Reshape2\"\n",
    "  top: \"Tile2\"\n",
    "  tile_param {\n",
    "    axis: 1\n",
    "    tiles: 10\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"slice_pos_norm\"\n",
    "  type: \"Eltwise\"\n",
    "  bottom: \"feat_p\"\n",
    "  bottom: \"Tile2\"\n",
    "  top: \"slice_pos_norm\"\n",
    "  eltwise_param {\n",
    "    operation: PROD\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reduction3\"\n",
    "  type: \"Reduction\"\n",
    "  bottom: \"feat_n\"\n",
    "  top: \"Reduction3\"\n",
    "  reduction_param {\n",
    "    operation: SUMSQ\n",
    "    axis: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Power3\"\n",
    "  type: \"Power\"\n",
    "  bottom: \"Reduction3\"\n",
    "  top: \"Power3\"\n",
    "  power_param {\n",
    "    power: -0.5\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reshape3\"\n",
    "  type: \"Reshape\"\n",
    "  bottom: \"Power3\"\n",
    "  top: \"Reshape3\"\n",
    "  reshape_param {\n",
    "    shape {\n",
    "      dim: 1\n",
    "    }\n",
    "    axis: -1\n",
    "    num_axes: 0\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Tile3\"\n",
    "  type: \"Tile\"\n",
    "  bottom: \"Reshape3\"\n",
    "  top: \"Tile3\"\n",
    "  tile_param {\n",
    "    axis: 1\n",
    "    tiles: 10\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"slice_neg_norm\"\n",
    "  type: \"Eltwise\"\n",
    "  bottom: \"feat_n\"\n",
    "  bottom: \"Tile3\"\n",
    "  top: \"slice_neg_norm\"\n",
    "  eltwise_param {\n",
    "    operation: PROD\n",
    "  }\n",
    "}\n",
    "\n",
    "############# Triplet Loss ###############\n",
    "layer {\n",
    "  name: \"tripletloss\"\n",
    "  type: \"Python\"\n",
    "  bottom: \"slice_anc_norm\"\n",
    "  bottom: \"slice_pos_norm\"\n",
    "  bottom: \"slice_neg_norm\"\n",
    "  top: \"loss\"\n",
    "  loss_weight: 1\n",
    "  python_param {\n",
    "    module: \"tripletloss_layer\"\n",
    "    layer: \"TripletLossLayer\"\n",
    "    param_str: '{\\\"margin\\\": 1.0}'\n",
    "  }\n",
    "  include {\n",
    "    phase: TRAIN\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pos_dist\"\n",
    "  type: \"Python\"\n",
    "  bottom: \"slice_anc_norm\"\n",
    "  bottom: \"slice_pos_norm\"\n",
    "  top: \"pos_dist\"\n",
    "  python_param {\n",
    "    module: \"tripletloss_layer\"\n",
    "    layer: \"PairwiseDistanceLayer\"\n",
    "    param_str: '{\\\"debug\\\": 0}'\n",
    "  }\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"neg_dist\"\n",
    "  type: \"Python\"\n",
    "  bottom: \"slice_anc_norm\"\n",
    "  bottom: \"slice_neg_norm\"\n",
    "  top: \"neg_dist\"\n",
    "  python_param {\n",
    "    module: \"tripletloss_layer\"\n",
    "    layer: \"PairwiseDistanceLayer\"\n",
    "    param_str: '{\\\"debug\\\": 0}'\n",
    "  }\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "}\n",
    "layer{\n",
    "  name: \"silence\"\n",
    "  type: \"Silence\"\n",
    "  bottom: \"label\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded 60000 images, 60000 labels\n",
      "sample image at 0 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 18, 18, 18, 126, 136, 175, 26, 166, 255, 247, 127, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 30, 36, 94, 154, 170, 253, 253, 253, 253, 253, 225, 172, 253, 242, 195, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 49, 238, 253, 253, 253, 253, 253, 253, 253, 253, 251, 93, 82, 82, 56, 39, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 219, 253, 253, 253, 253, 253, 198, 182, 247, 241, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 80, 156, 107, 253, 253, 205, 11, 0, 43, 154, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14, 1, 154, 253, 90, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 139, 253, 190, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11, 190, 253, 70, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 35, 241, 225, 160, 108, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 81, 240, 253, 253, 119, 25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 45, 186, 253, 253, 150, 27, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 16, 93, 252, 253, 187, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 249, 253, 249, 64, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 46, 130, 183, 253, 253, 207, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 39, 148, 229, 253, 253, 253, 250, 182, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 24, 114, 221, 253, 253, 253, 253, 201, 78, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 23, 66, 213, 253, 253, 253, 253, 198, 81, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 18, 171, 219, 253, 253, 253, 253, 195, 80, 9, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 55, 172, 226, 253, 253, 253, 253, 244, 133, 11, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 136, 253, 253, 253, 212, 135, 132, 16, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "from mnist import MNIST\n",
    "import os\n",
    "mnist_data_dir = os.path.join(caffe_root, 'data/mnist')\n",
    "mndata = MNIST(mnist_data_dir)\n",
    "images, labels = mndata.load_training()\n",
    "print('loaded {} images, {} labels'.format(len(images), len(labels)))\n",
    "print('sample image at 0 = {}'.format(images[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "from StringIO import StringIO\n",
    "\n",
    "img_dir = '/home/researcher/caffe-tripletloss/examples/tripletloss/mnist/images'\n",
    "if not os.path.exists(img_dir):\n",
    "    os.makedirs(img_dir)\n",
    "\n",
    "# create a training list\n",
    "triplet_dict = {'anchor': None, 'positive': None, 'negative': None}\n",
    "anchor_list = StringIO()\n",
    "pos_list = StringIO()\n",
    "neg_list = StringIO()\n",
    "batch_str = StringIO()\n",
    "triplet_no = 0\n",
    "batch_size = 0\n",
    "for i, l in zip(images, labels):\n",
    "    array = np.array(i)\n",
    "    img = array.reshape((28, 28))\n",
    "    \n",
    "    if triplet_dict['anchor'] is None:\n",
    "        # this becomes an anchor\n",
    "        triplet_dict['anchor'] = [img, l]\n",
    "    elif triplet_dict['positive'] is None:\n",
    "        # check if this is the same label\n",
    "        if triplet_dict['anchor'][1] == l:\n",
    "            # this becomes a postive one\n",
    "            triplet_dict['positive'] = [img, l]\n",
    "    elif triplet_dict['anchor'][1] != l:\n",
    "        # this becomes a negative one\n",
    "        triplet_dict['negative'] = [img, l]\n",
    "        \n",
    "    if triplet_dict['negative'] is None:\n",
    "        continue\n",
    "    \n",
    "    # write\n",
    "    anchor_path = os.path.join(img_dir, '{}_anchor.jpg'.format(triplet_no))\n",
    "    pos_path = os.path.join(img_dir, '{}_positive.jpg'.format(triplet_no))\n",
    "    neg_path = os.path.join(img_dir, '{}_negative.jpg'.format(triplet_no))\n",
    "    \n",
    "    # image\n",
    "    cv2.imwrite(anchor_path, triplet_dict['anchor'][0])\n",
    "    cv2.imwrite(pos_path, triplet_dict['positive'][0])\n",
    "    cv2.imwrite(neg_path, triplet_dict['negative'][0])\n",
    "    \n",
    "    # sample\n",
    "    anchor_list.write('{} {}\\n'.format(anchor_path, triplet_dict['anchor'][1]))\n",
    "    pos_list.write('{} {}\\n'.format(pos_path, triplet_dict['positive'][1]))\n",
    "    neg_list.write('{} {}\\n'.format(neg_path, triplet_dict['negative'][1]))\n",
    "    \n",
    "    # reset\n",
    "    triplet_dict['anchor'] = None\n",
    "    triplet_dict['positive'] = None\n",
    "    triplet_dict['negative'] = None\n",
    "    \n",
    "    triplet_no += 1\n",
    "    batch_size += 1\n",
    "    \n",
    "    if batch_size == 64:\n",
    "        # write anchors first\n",
    "        batch_str.write(anchor_list.getvalue())\n",
    "        anchor_list.close()\n",
    "        anchor_list = StringIO()\n",
    "        # positive\n",
    "        batch_str.write(pos_list.getvalue())\n",
    "        pos_list.close()\n",
    "        pos_list = StringIO()\n",
    "        # negative\n",
    "        batch_str.write(neg_list.getvalue())\n",
    "        neg_list.close()\n",
    "        neg_list = StringIO()\n",
    "        # reset\n",
    "        batch_size = 0\n",
    "    \n",
    "# finally, write sample list\n",
    "with open(os.path.join(img_dir, '../' ,'trainlist_64.txt'), 'w') as f:\n",
    "    f.write(batch_str.getvalue())\n",
    "    batch_str.close()\n",
    "    anchor_list.close()\n",
    "    pos_list.close()\n",
    "    neg_list.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tripletloss/mnist_tripletloss_solver_10.prototxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile tripletloss/mnist_tripletloss_solver_10.prototxt\n",
    "# The train/test net protocol buffer definition\n",
    "train_net: \"/home/researcher/caffe-tripletloss/examples/tripletloss/mnist_tripletloss_train_test_10.prototxt\"\n",
    "test_net: \"/home/researcher/caffe-tripletloss/examples/tripletloss/mnist_tripletloss_train_test_10.prototxt\"\n",
    "# samples = 192 * 77 = 14784\n",
    "test_iter: 77\n",
    "# test at every epoch\n",
    "test_interval: 77\n",
    "# The base learning rate, momentum and the weight decay of the network.\n",
    "base_lr: 0.01\n",
    "momentum: 0.9\n",
    "weight_decay: 0.0005\n",
    "# The learning rate policy\n",
    "lr_policy: \"inv\"\n",
    "gamma: 0.0001\n",
    "power: 0.75\n",
    "# Display every epoch\n",
    "display: 77\n",
    "# The maximum number of iterations = 10 epochs\n",
    "max_iter: 770\n",
    "# snapshot intermediate results at every epoch\n",
    "snapshot: 77\n",
    "snapshot_prefix: \"/home/researcher/caffe-tripletloss/examples/tripletloss/mnist/mnist_tripletloss\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "caffe.set_device(0)\n",
    "caffe.set_mode_gpu()\n",
    "\n",
    "# reset solver to avoid a continuous training over multiple runs\n",
    "solver = None\n",
    "solver = caffe.SGDSolver('/home/researcher/caffe-tripletloss/examples/tripletloss/mnist_tripletloss_solver_10.prototxt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('triplet_data', (192, 3, 28, 28)),\n",
       " ('label', (192,)),\n",
       " ('anchor', (64, 3, 28, 28)),\n",
       " ('positive', (64, 3, 28, 28)),\n",
       " ('negative', (64, 3, 28, 28)),\n",
       " ('conv1', (64, 20, 24, 24)),\n",
       " ('pool1', (64, 20, 12, 12)),\n",
       " ('conv2', (64, 50, 8, 8)),\n",
       " ('pool2', (64, 50, 4, 4)),\n",
       " ('ip1', (64, 500)),\n",
       " ('feat', (64, 10)),\n",
       " ('feat_ip2_0_split_0', (64, 10)),\n",
       " ('feat_ip2_0_split_1', (64, 10)),\n",
       " ('conv1_p', (64, 20, 24, 24)),\n",
       " ('pool1_p', (64, 20, 12, 12)),\n",
       " ('conv2_p', (64, 50, 8, 8)),\n",
       " ('pool2_p', (64, 50, 4, 4)),\n",
       " ('ip1_p', (64, 500)),\n",
       " ('feat_p', (64, 10)),\n",
       " ('feat_p_ip2_p_0_split_0', (64, 10)),\n",
       " ('feat_p_ip2_p_0_split_1', (64, 10)),\n",
       " ('conv1_n', (64, 20, 24, 24)),\n",
       " ('pool1_n', (64, 20, 12, 12)),\n",
       " ('conv2_n', (64, 50, 8, 8)),\n",
       " ('pool2_n', (64, 50, 4, 4)),\n",
       " ('ip1_n', (64, 500)),\n",
       " ('feat_n', (64, 10)),\n",
       " ('feat_n_ip2_n_0_split_0', (64, 10)),\n",
       " ('feat_n_ip2_n_0_split_1', (64, 10)),\n",
       " ('Reduction1', (64,)),\n",
       " ('Power1', (64,)),\n",
       " ('Reshape1', (64, 1)),\n",
       " ('Tile1', (64, 10)),\n",
       " ('slice_anc_norm', (64, 10)),\n",
       " ('Reduction2', (64,)),\n",
       " ('Power2', (64,)),\n",
       " ('Reshape2', (64, 1)),\n",
       " ('Tile2', (64, 10)),\n",
       " ('slice_pos_norm', (64, 10)),\n",
       " ('Reduction3', (64,)),\n",
       " ('Power3', (64,)),\n",
       " ('Reshape3', (64, 1)),\n",
       " ('Tile3', (64, 10)),\n",
       " ('slice_neg_norm', (64, 10)),\n",
       " ('loss', (1,))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# each output is (batch size, feature dim, spatial dim)\n",
    "[(k, v.data.shape) for k, v in solver.net.blobs.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('conv1', (20, 3, 5, 5)),\n",
       " ('conv2', (50, 20, 5, 5)),\n",
       " ('ip1', (500, 800)),\n",
       " ('ip2', (10, 500)),\n",
       " ('conv1_p', (20, 3, 5, 5)),\n",
       " ('conv2_p', (50, 20, 5, 5)),\n",
       " ('ip1_p', (500, 800)),\n",
       " ('ip2_p', (10, 500)),\n",
       " ('conv1_n', (20, 3, 5, 5)),\n",
       " ('conv2_n', (50, 20, 5, 5)),\n",
       " ('ip1_n', (500, 800)),\n",
       " ('ip2_n', (10, 500))]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# just print the weight sizes (we'll omit the biases)\n",
    "[(k, v[0].data.shape) for k, v in solver.net.params.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss at epoch 0 = [ 0.85033965]\n",
      "loss at epoch 1 = [ 0.99302012]\n",
      "loss at epoch 2 = [ 0.8766827]\n",
      "loss at epoch 3 = [ 0.55279803]\n",
      "loss at epoch 4 = [ 0.40801919]\n",
      "loss at epoch 5 = [ 0.30903319]\n",
      "loss at epoch 6 = [ 0.18014039]\n",
      "loss at epoch 7 = [ 0.1296652]\n",
      "loss at epoch 8 = [ 0.11750305]\n",
      "loss at epoch 9 = [ 0.05959765]\n",
      "loss at epoch 10 = [ 0.07006246]\n",
      "loss at epoch 11 = [ 0.05378543]\n",
      "loss at epoch 12 = [ 0.06332132]\n",
      "loss at epoch 13 = [ 0.05327535]\n",
      "loss at epoch 14 = [ 0.04025308]\n",
      "loss at epoch 15 = [ 0.02750574]\n",
      "loss at epoch 16 = [ 0.02782862]\n",
      "loss at epoch 17 = [ 0.03689694]\n",
      "loss at epoch 18 = [ 0.01833757]\n",
      "loss at epoch 19 = [ 0.04366427]\n",
      "CPU times: user 2min 33s, sys: 10.9 s, total: 2min 44s\n",
      "Wall time: 2min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "itr_per_epoch = 77\n",
    "niter = itr_per_epoch * 20\n",
    "\n",
    "train_loss = np.zeros(niter)\n",
    "\n",
    "# the main solver loop\n",
    "for it in range(niter):\n",
    "    solver.step(1)  # SGD by Caffe\n",
    "    \n",
    "    # store the train loss\n",
    "    loss = solver.net.blobs['loss'].data\n",
    "    \n",
    "    # output every epoch\n",
    "    if it % itr_per_epoch == 0:\n",
    "        print('loss at epoch {} = {}'.format(it/itr_per_epoch, loss))\n",
    "    \n",
    "    train_loss[it] = loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Deploy Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting tripletloss/mnist_tripletloss_deploy_10.prototxt\n"
     ]
    }
   ],
   "source": [
    "%%writefile tripletloss/mnist_tripletloss_deploy_10.prototxt\n",
    "name: \"mnist_tripletloss_deploy_10\"\n",
    "layer {\n",
    "  name: \"data\"\n",
    "  type: \"Input\"\n",
    "  top: \"data\"\n",
    "  input_param { shape: { dim: 2 dim: 3 dim: 28 dim: 28 } }\n",
    "}\n",
    "layer {\n",
    "  name: \"slice_pair\"\n",
    "  type: \"Slice\"\n",
    "  bottom: \"data\"\n",
    "  top: \"foo\"\n",
    "  top: \"bar\"\n",
    "  slice_param {\n",
    "    slice_dim: 0\n",
    "  }\n",
    "}\n",
    "\n",
    "# foo => anchor\n",
    "# bar => positive\n",
    "\n",
    "################# ANCHOR #############\n",
    "layer {\n",
    "  name: \"conv1\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"foo\"\n",
    "  top: \"conv1\"\n",
    "  param {\n",
    "    name: \"conv1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1\"\n",
    "  top: \"pool1\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv2\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool1\"\n",
    "  top: \"conv2\"\n",
    "  param {\n",
    "    name: \"conv2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool2\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv2\"\n",
    "  top: \"pool2\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool2\"\n",
    "  top: \"ip1\"\n",
    "  param {\n",
    "    name: \"ip1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip1\"\n",
    "  top: \"ip1\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip2\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip1\"\n",
    "  top: \"feat\"\n",
    "  param {\n",
    "    name: \"ip2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "###################### POSITIVE ###################\n",
    "\n",
    "layer {\n",
    "  name: \"conv1_p\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"bar\"\n",
    "  top: \"conv1_p\"\n",
    "  param {\n",
    "    name: \"conv1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 20\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool1_p\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv1_p\"\n",
    "  top: \"pool1_p\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"conv2_p\"\n",
    "  type: \"Convolution\"\n",
    "  bottom: \"pool1_p\"\n",
    "  top: \"conv2_p\"\n",
    "  param {\n",
    "    name: \"conv2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"conv2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  convolution_param {\n",
    "    num_output: 50\n",
    "    kernel_size: 5\n",
    "    stride: 1\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"pool2_p\"\n",
    "  type: \"Pooling\"\n",
    "  bottom: \"conv2_p\"\n",
    "  top: \"pool2_p\"\n",
    "  pooling_param {\n",
    "    pool: MAX\n",
    "    kernel_size: 2\n",
    "    stride: 2\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"ip1_p\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"pool2_p\"\n",
    "  top: \"ip1_p\"\n",
    "  param {\n",
    "    name: \"ip1_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip1_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 500\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"relu1_p\"\n",
    "  type: \"ReLU\"\n",
    "  bottom: \"ip1_p\"\n",
    "  top: \"ip1_p\"\n",
    "}\n",
    "layer {\n",
    "  name: \"ip2_p\"\n",
    "  type: \"InnerProduct\"\n",
    "  bottom: \"ip1_p\"\n",
    "  top: \"feat_p\"\n",
    "  param {\n",
    "    name: \"ip2_w\"\n",
    "    lr_mult: 1\n",
    "  }\n",
    "  param {\n",
    "    name: \"ip2_b\"\n",
    "    lr_mult: 2\n",
    "  }\n",
    "  inner_product_param {\n",
    "    num_output: 10\n",
    "    weight_filler {\n",
    "      type: \"xavier\"\n",
    "    }\n",
    "    bias_filler {\n",
    "      type: \"constant\"\n",
    "    }\n",
    "  }\n",
    "}\n",
    "\n",
    "############# L2 Normalization ############\n",
    "\n",
    "layer {\n",
    "  name: \"Reduction1\"\n",
    "  type: \"Reduction\"\n",
    "  bottom: \"feat\"\n",
    "  top: \"Reduction1\"\n",
    "  reduction_param {\n",
    "    operation: SUMSQ\n",
    "    axis: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Power1\"\n",
    "  type: \"Power\"\n",
    "  bottom: \"Reduction1\"\n",
    "  top: \"Power1\"\n",
    "  power_param {\n",
    "    power: -0.5\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reshape1\"\n",
    "  type: \"Reshape\"\n",
    "  bottom: \"Power1\"\n",
    "  top: \"Reshape1\"\n",
    "  reshape_param {\n",
    "    shape {\n",
    "      dim: 1\n",
    "    }\n",
    "    axis: -1\n",
    "    num_axes: 0\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Tile1\"\n",
    "  type: \"Tile\"\n",
    "  bottom: \"Reshape1\"\n",
    "  top: \"Tile1\"\n",
    "  tile_param {\n",
    "    axis: 1\n",
    "    tiles: 10\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"slice_anc_norm\"\n",
    "  type: \"Eltwise\"\n",
    "  bottom: \"feat\"\n",
    "  bottom: \"Tile1\"\n",
    "  top: \"slice_anc_norm\"\n",
    "  eltwise_param {\n",
    "    operation: PROD\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reduction2\"\n",
    "  type: \"Reduction\"\n",
    "  bottom: \"feat_p\"\n",
    "  top: \"Reduction2\"\n",
    "  reduction_param {\n",
    "    operation: SUMSQ\n",
    "    axis: 1\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Power2\"\n",
    "  type: \"Power\"\n",
    "  bottom: \"Reduction2\"\n",
    "  top: \"Power2\"\n",
    "  power_param {\n",
    "    power: -0.5\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Reshape2\"\n",
    "  type: \"Reshape\"\n",
    "  bottom: \"Power2\"\n",
    "  top: \"Reshape2\"\n",
    "  reshape_param {\n",
    "    shape {\n",
    "      dim: 1\n",
    "    }\n",
    "    axis: -1\n",
    "    num_axes: 0\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"Tile2\"\n",
    "  type: \"Tile\"\n",
    "  bottom: \"Reshape2\"\n",
    "  top: \"Tile2\"\n",
    "  tile_param {\n",
    "    axis: 1\n",
    "    tiles: 10\n",
    "  }\n",
    "}\n",
    "layer {\n",
    "  name: \"slice_pos_norm\"\n",
    "  type: \"Eltwise\"\n",
    "  bottom: \"feat_p\"\n",
    "  bottom: \"Tile2\"\n",
    "  top: \"slice_pos_norm\"\n",
    "  eltwise_param {\n",
    "    operation: PROD\n",
    "  }\n",
    "}\n",
    "\n",
    "############# Triplet Loss ###############\n",
    "layer {\n",
    "  name: \"pos_dist\"\n",
    "  type: \"Python\"\n",
    "  bottom: \"slice_anc_norm\"\n",
    "  bottom: \"slice_pos_norm\"\n",
    "  top: \"pos_dist\"\n",
    "  python_param {\n",
    "    module: \"tripletloss_layer\"\n",
    "    layer: \"PairwiseDistanceLayer\"\n",
    "    param_str: '{\\\"debug\\\": 0}'\n",
    "  }\n",
    "  include {\n",
    "    phase: TEST\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# display plots in this notebook\n",
    "%matplotlib inline\n",
    "\n",
    "# set display defaults\n",
    "plt.rcParams['figure.figsize'] = (10, 10)        # large images\n",
    "plt.rcParams['image.interpolation'] = 'nearest'  # don't interpolate: show square pixels\n",
    "plt.rcParams['image.cmap'] = 'gray'  # use grayscale output rather than a (potentially misleading) color heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_def = caffe_root + 'examples/tripletloss/mnist_tripletloss_deploy_10.prototxt'\n",
    "model_weights = caffe_root + 'examples/tripletloss/mnist/mnist_tripletloss_iter_1463.caffemodel'\n",
    "\n",
    "net = caffe.Net(model_def,      # defines the structure of the model\n",
    "                model_weights,  # contains the trained weights\n",
    "                caffe.TEST)     # use test mode (e.g., don't perform dropout)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_anc shape = (28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f87fdd3c790>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAJCCAYAAADOe7N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "img_anc = cv2.imread('/home/researcher/caffe-tripletloss/examples/tripletloss/mnist/images/0_anchor.jpg')\n",
    "print('img_anc shape = {}'.format(img_anc.shape))\n",
    "plt.imshow(img_anc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_pos shape = (28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f885aff4990>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAJCCAYAAADOe7N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEkUAAJUoAgCo6v8BHUgriDxq72UAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_pos = cv2.imread('/home/researcher/caffe-tripletloss/examples/tripletloss/mnist/images/0_positive.jpg')\n",
    "print('img_pos shape = {}'.format(img_pos.shape))\n",
    "plt.imshow(img_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_neg shape = (28, 28, 3)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f87fde2ac10>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkUAAAJCCAYAAADOe7N5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQCWKAAAqUQQAUNX/BRMTdvcruZIQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "img_neg = cv2.imread('/home/researcher/caffe-tripletloss/examples/tripletloss/mnist/images/0_negative.jpg')\n",
    "print('img_neg shape = {}'.format(img_neg.shape))\n",
    "plt.imshow(img_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img_anc_transposed shape = (3, 28, 28)\n",
      "img_pos_transposed shape = (3, 28, 28)\n",
      "img_neg_transposed shape = (3, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "img_anc_transposed = img_anc.transpose(2, 0, 1)\n",
    "print('img_anc_transposed shape = {}'.format(img_anc_transposed.shape))\n",
    "img_pos_transposed = img_pos.transpose(2, 0, 1)\n",
    "print('img_pos_transposed shape = {}'.format(img_pos_transposed.shape))\n",
    "img_neg_transposed = img_neg.transpose(2, 0, 1)\n",
    "print('img_neg_transposed shape = {}'.format(img_neg_transposed.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist between anc and pos = [ 0.32835513]\n"
     ]
    }
   ],
   "source": [
    "# set a pair data\n",
    "net.blobs['data'].data[...] = np.array([img_anc_transposed, img_pos_transposed])\n",
    "\n",
    "# calculate distance\n",
    "net.forward()\n",
    "\n",
    "dist = net.blobs['pos_dist'].data\n",
    "print('dist between anc and pos = {}'.format(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dist between anc and neg = [ 1.63734376]\n"
     ]
    }
   ],
   "source": [
    "# set a pair data\n",
    "net.blobs['data'].data[...] = np.array([img_anc_transposed, img_neg_transposed])\n",
    "\n",
    "# calculate distance\n",
    "net.forward()\n",
    "\n",
    "dist = net.blobs['pos_dist'].data\n",
    "print('dist between anc and neg = {}'.format(dist))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Caffe + Triplet",
   "language": "python",
   "name": "caffe_triplet"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
